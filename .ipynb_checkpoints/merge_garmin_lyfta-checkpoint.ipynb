{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7db2295a",
   "metadata": {},
   "source": [
    "# Merge Garmin .FIT and Lyfta CSV\n",
    "\n",
    "This notebook extracts heart-rate time-series from a Garmin `.fit` file and merges it set-by-set with a Lyfta CSV export (the CSV format you provided). It includes parsing, visualization, HR peak-based set detection, and produces a merged CSV with per-set HR metrics.\n",
    "\n",
    "**How to use**:\n",
    "1. Upload your `Lyfta` CSV and the Garmin `.fit` file into the environment or set their paths in the **Run the merge** cell.\n",
    "2. Run the cells sequentially. Tune peak-detection parameters interactively if results need adjustments.\n",
    "\n",
    "**Notes**:\n",
    "- This notebook expects Python packages `fitparse`, `pandas`, `numpy`, `scipy`, and `matplotlib`. If they're missing, run the install cell below.\n",
    "- The FIT parsing uses `fitparse`; if you prefer `fitdecode` you can adapt the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57311b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.10\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python3 -V\n",
    "# Install required packages (uncomment to run in your environment)\n",
    "# pip install fitparse pandas numpy scipy matplotlib\n",
    "\n",
    "# If running on a managed environment where pip is restricted, install in a venv or run locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c751cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fitparse\n",
      "  Downloading fitparse-1.2.0.tar.gz (65 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: fitparse\n",
      "  Building wheel for fitparse (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fitparse: filename=fitparse-1.2.0-py3-none-any.whl size=68199 sha256=f3804a36c104aae74c08a5f8c8b35e750578057c37668c97e77c5521f126aba8\n",
      "  Stored in directory: /home/ainesh/.cache/pip/wheels/49/df/4b/3fa676f0a6dd88074d9e09dbaa428e32f43a59a3c01bb95fe8\n",
      "Successfully built fitparse\n",
      "Installing collected packages: fitparse\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 13] Permission denied: '/usr/local/bin/fitdump'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "imports ok\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "!pip install fitparse\n",
    "\n",
    "# FIT parsing\n",
    "from fitparse import FitFile\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "print('imports ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e154b99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_lyfta_csv(path):\n",
    "    df = pd.read_csv(path)\n",
    "    if df.empty:\n",
    "        raise ValueError('Lyfta CSV empty')\n",
    "    try:\n",
    "        workout_start = pd.to_datetime(df.loc[0, 'Date'])\n",
    "    except Exception:\n",
    "        workout_start = pd.to_datetime(df.loc[0, 'Date'], infer_datetime_format=True)\n",
    "    workout_info = {\n",
    "        'title': df.loc[0, 'Title'],\n",
    "        'start_time': workout_start.to_pydatetime(),\n",
    "        'duration_text': df.loc[0, 'Duration'] if 'Duration' in df.columns else None,\n",
    "        'n_sets': len(df)\n",
    "    }\n",
    "    sets = []\n",
    "    for i, row in df.iterrows():\n",
    "        sets.append({\n",
    "            'set_index': int(i),\n",
    "            'exercise': row.get('Exercise'),\n",
    "            'weight': row.get('Weight'),\n",
    "            'reps': row.get('Reps')\n",
    "        })\n",
    "    return workout_info, sets\n",
    "\n",
    "\n",
    "def parse_fit_file(fit_path):\n",
    "    fitfile = FitFile(fit_path)\n",
    "    records = []\n",
    "    activity_start = None\n",
    "    total_elapsed = None\n",
    "    garmin_sets = []\n",
    "    for msg in fitfile.get_messages():\n",
    "        name = msg.name\n",
    "        if name == 'file_id':\n",
    "            for d in msg:\n",
    "                if d.name == 'time_created' and d.value:\n",
    "                    activity_start = d.value if activity_start is None else activity_start\n",
    "        elif name == 'session':\n",
    "            for d in msg:\n",
    "                if d.name == 'start_time' and d.value:\n",
    "                    activity_start = d.value\n",
    "                if d.name in ('total_elapsed_time','total_timer_time') and d.value:\n",
    "                    total_elapsed = float(d.value)\n",
    "        elif name == 'lap':\n",
    "            lap_start = None\n",
    "            lap_end = None\n",
    "            for d in msg:\n",
    "                if d.name == 'start_time':\n",
    "                    lap_start = d.value\n",
    "                if d.name == 'timestamp':\n",
    "                    lap_end = d.value\n",
    "            if lap_start and lap_end:\n",
    "                garmin_sets.append({'start': lap_start, 'end': lap_end})\n",
    "\n",
    "    # collect records\n",
    "    fitfile = FitFile(fit_path)\n",
    "    for record in fitfile.get_messages('record'):\n",
    "        rec = {}\n",
    "        for d in record:\n",
    "            rec[d.name] = d.value\n",
    "        if 'timestamp' in rec:\n",
    "            hr = rec.get('heart_rate', None)\n",
    "            records.append({'timestamp': rec['timestamp'], 'heart_rate': hr})\n",
    "\n",
    "    hr_df = pd.DataFrame(records)\n",
    "    hr_df = hr_df.dropna(subset=['timestamp']).drop_duplicates(subset=['timestamp'])\n",
    "    hr_df['timestamp'] = pd.to_datetime(hr_df['timestamp'])\n",
    "    hr_df = hr_df.sort_values('timestamp').reset_index(drop=True)\n",
    "    if hr_df['heart_rate'].isna().all():\n",
    "        raise ValueError('FIT HR records exist but heart_rate values are all missing.')\n",
    "    hr_df['heart_rate'] = hr_df['heart_rate'].ffill().bfill().astype(float)\n",
    "    if activity_start is None:\n",
    "        activity_start = hr_df['timestamp'].iloc[0]\n",
    "    if total_elapsed is None:\n",
    "        total_elapsed = (hr_df['timestamp'].iloc[-1] - hr_df['timestamp'].iloc[0]).total_seconds()\n",
    "    return {'activity_start': activity_start.to_pydatetime(), 'total_elapsed': float(total_elapsed), 'hr_df': hr_df, 'garmin_sets': garmin_sets}\n",
    "\n",
    "\n",
    "def detect_sets_from_hr(hr_df, expected_n_sets, min_peak_distance_seconds=30, min_peak_prominence=6):\n",
    "    df = hr_df.copy().set_index('timestamp')\n",
    "    df = df.resample('1S').mean().interpolate()\n",
    "    hr = df['heart_rate'].values\n",
    "    times = df.index.to_pydatetime()\n",
    "    if len(hr) < 5:\n",
    "        return []\n",
    "    baseline = np.median(hr[:max(1, min(30, len(hr)))])\n",
    "    distance = int(min_peak_distance_seconds)\n",
    "    peaks, props = find_peaks(hr, distance=distance, prominence=min_peak_prominence)\n",
    "    if len(peaks) == 0:\n",
    "        return []\n",
    "    prominences = props.get('prominences', np.ones(len(peaks)))\n",
    "    peak_info = sorted(zip(peaks, prominences), key=lambda x: -x[1])\n",
    "    selected_peaks = sorted([p for p, _ in peak_info[:expected_n_sets]])\n",
    "    windows = []\n",
    "    for p in selected_peaks:\n",
    "        peak_time = times[p]\n",
    "        thr = baseline + 0.33 * prominences[list(peaks).index(p)] if len(prominences)>0 else baseline + 3\n",
    "        left = p\n",
    "        while left > 0 and hr[left] > thr:\n",
    "            left -= 1\n",
    "        right = p\n",
    "        while right < len(hr)-1 and hr[right] > thr:\n",
    "            right += 1\n",
    "        start = times[left]\n",
    "        end = times[right]\n",
    "        windows.append({'start': start, 'end': end, 'peak': peak_time})\n",
    "    return windows\n",
    "\n",
    "\n",
    "def equal_split_windows(activity_start, activity_end, n):\n",
    "    total = (activity_end - activity_start).total_seconds()\n",
    "    windows = []\n",
    "    for i in range(n):\n",
    "        s = activity_start + timedelta(seconds=(i * total / n))\n",
    "        e = activity_start + timedelta(seconds=((i+1) * total / n))\n",
    "        windows.append({'start': s, 'end': e, 'peak': s + (e - s)/2})\n",
    "    return windows\n",
    "\n",
    "\n",
    "def compute_metrics_for_window(hr_df, window):\n",
    "    s = pd.to_datetime(window['start'])\n",
    "    e = pd.to_datetime(window['end'])\n",
    "    mask = (hr_df['timestamp'] >= s) & (hr_df['timestamp'] <= e)\n",
    "    slice_df = hr_df.loc[mask]\n",
    "    if slice_df.empty:\n",
    "        nearest_idx = (hr_df['timestamp'] - s).abs().idxmin()\n",
    "        sample = hr_df.loc[nearest_idx]\n",
    "        avg_hr = float(sample['heart_rate'])\n",
    "        max_hr = float(sample['heart_rate'])\n",
    "        duration = (e - s).total_seconds()\n",
    "        hr_curve = [{'ts': str(sample['timestamp']), 'hr': sample['heart_rate']}]\n",
    "        return {'avg_hr': avg_hr, 'max_hr': max_hr, 'duration': duration, 'hr_curve': hr_curve}\n",
    "    avg_hr = float(slice_df['heart_rate'].mean())\n",
    "    max_hr = float(slice_df['heart_rate'].max())\n",
    "    duration = (e - s).total_seconds()\n",
    "    hr_curve = [{'ts': str(r['timestamp']), 'hr': float(r['heart_rate'])} for _, r in slice_df.iterrows()]\n",
    "    return {'avg_hr': avg_hr, 'max_hr': max_hr, 'duration': duration, 'hr_curve': hr_curve}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e9a4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: plot HR curve and mark detected peaks/windows\n",
    "def plot_hr_and_windows(hr_df, windows=None, title='HR'): \n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(hr_df['timestamp'], hr_df['heart_rate'], label='HR')\n",
    "    if windows:\n",
    "        for i,w in enumerate(windows):\n",
    "            plt.axvspan(pd.to_datetime(w['start']), pd.to_datetime(w['end']), alpha=0.2, label=f'set {i}')\n",
    "            plt.axvline(pd.to_datetime(w['peak']), linestyle='--', alpha=0.6)\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('bpm')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print('plot helper ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1588efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the merge on your files - set paths here\n",
    "LYFTA_CSV = 'lyfta_sample.csv'  # <-- change to your Lyfta CSV path\n",
    "FIT_PATH = '/mnt/data/21159045593_ACTIVITY.fit'  # <-- change if needed\n",
    "OUT_CSV = 'merged_workout.csv'\n",
    "\n",
    "# Quick existence checks\n",
    "print('Files exist?', os.path.exists(LYFTA_CSV), os.path.exists(FIT_PATH))\n",
    "\n",
    "workout_info, lyfta_sets = parse_lyfta_csv(LYFTA_CSV)\n",
    "fit_parsed = parse_fit_file(FIT_PATH)\n",
    "print('Lyfta start:', workout_info['start_time'], 'Sets:', workout_info['n_sets'])\n",
    "print('Garmin start:', fit_parsed['activity_start'], 'elapsed(s):', fit_parsed['total_elapsed'])\n",
    "\n",
    "# Attempt detection\n",
    "windows = detect_sets_from_hr(fit_parsed['hr_df'], expected_n_sets=workout_info['n_sets'], min_peak_distance_seconds=20, min_peak_prominence=4)\n",
    "if not windows or len(windows) != workout_info['n_sets']:\n",
    "    print('Detected windows:', len(windows), 'expected:', workout_info['n_sets'], '-> falling back to equal split')\n",
    "    activity_end = fit_parsed['activity_start'] + timedelta(seconds=fit_parsed['total_elapsed'])\n",
    "    windows = equal_split_windows(fit_parsed['activity_start'], activity_end, workout_info['n_sets'])\n",
    "\n",
    "# Compute metrics\n",
    "merged_rows = []\n",
    "hr_df = fit_parsed['hr_df']\n",
    "for idx, set_rec in enumerate(lyfta_sets):\n",
    "    w = windows[idx]\n",
    "    metrics = compute_metrics_for_window(hr_df, w)\n",
    "    merged_rows.append({\n",
    "        'set_index': idx,\n",
    "        'exercise': set_rec['exercise'],\n",
    "        'weight': set_rec['weight'],\n",
    "        'reps': set_rec['reps'],\n",
    "        'set_start': w['start'],\n",
    "        'set_end': w['end'],\n",
    "        'set_duration_s': metrics['duration'],\n",
    "        'avg_hr': metrics['avg_hr'],\n",
    "        'max_hr': metrics['max_hr']\n",
    "    })\n",
    "\n",
    "out_df = pd.DataFrame(merged_rows)\n",
    "out_df.to_csv(OUT_CSV, index=False)\n",
    "print('Saved merged to', OUT_CSV)\n",
    "\n",
    "# Plot for visual check\n",
    "plot_hr_and_windows(hr_df, windows, title=f\"Workout {workout_info['title']} - HR with detected sets\")\n",
    "\n",
    "# Display summary\n",
    "print('\\nWorkout summary:')\n",
    "print('Total sets:', len(out_df))\n",
    "print('Avg HR across sets:', out_df['avg_hr'].mean())\n",
    "print('Max HR across sets:', out_df['max_hr'].max())\n",
    "\n",
    "out_df.head(20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
